---

ID: [[202302110903]]
Title: 泰德姜纽约客文章机器翻译版
Tags: #DPRH #2023-02-11 #chatGPT #AI写作 #gc8 #好中文
Date: Saturday February 11, 2023 at 09:03:02 GMT+8

---
插图：Vivek Thakker

技术年鉴

ChatGPT是网络上的一个模糊的JPEG图片

OpenAI的聊天机器人提供转述，而谷歌则提供引语。我们更喜欢哪一个？

作者：Ted Chiang

2023年2月9日

2013年，一家德国建筑公司的工人注意到他们的施乐复印机有一些奇怪的地方：当他们复印一所房子的平面图时，复印件与原件有细微但重要的区别。在原始平面图中，该房屋的三个房间都有一个长方形，说明其面积：房间的面积分别为14.13、21.11和17.42平方米。然而，在复印件中，所有三个房间都被标注为14.13平方米的面积。该公司联系了计算机科学家David Kriesel来调查这个看似不可思议的结果。他们需要一位计算机科学家，因为现代施乐公司的复印机并不使用1960年代流行的物理xerographic过程。相反，它以数字方式扫描文件，然后打印出产生的图像文件。结合这一事实，几乎每一个数字图像文件都被压缩以节省空间，而这个谜团的解决方案也开始出现。

压缩文件需要两个步骤：首先是编码，在这个过程中，文件被转换成一个更紧凑的格式，然后是解码，这个过程被逆转了。如果恢复的文件与原始文件相同，那么压缩过程被描述为无损的：没有信息被丢弃。相比之下，如果恢复的文件只是原始文件的一个近似值，则压缩被描述为有损的：一些信息被丢弃，现在无法恢复。无损压缩通常用于文本文件和计算机程序，因为在这些领域，即使一个错误的字符也有可能造成灾难性的后果。有损压缩通常用于照片、音频和视频，在这种情况下，绝对的准确性并不重要。大多数时候，我们不会注意到一张照片、一首歌曲或一部电影没有完美再现。只有当文件被挤压得非常紧时，保真度的损失才会变得更容易被察觉。在这些情况下，我们会注意到所谓的压缩假象：最小的jpeg和mpeg图像的模糊性，或低比特率MP3的尖锐声音。

施乐公司的复印机使用一种称为jbig2的有损压缩格式，设计用于黑白图像。为了节省空间，复印机识别图像中看起来相似的区域，并为所有这些区域存储一个副本；当文件被解压缩时，它重复使用该副本来重建图像。事实证明，复印机判断指定房间面积的标签足够相似，它只需要存储其中的一个--14.13，而且在打印平面图时，它对所有三个房间都重复使用这个标签。

施乐影印机使用有损压缩格式而不是无损压缩格式这一事实本身并不是一个问题。问题是，复印机以一种微妙的方式降低了图像的质量，在这种情况下，压缩伪影并不能立即被识别出来。如果复印机只是产生了模糊的打印件，每个人都会知道它们不是原件的准确复制品。导致问题的原因是，复印机产生的数字是可读的，但不正确；它使复印件看起来是准确的，但实际上并不准确。(2014年，施乐公司发布了一个补丁来纠正这个问题）。

我认为，在我们考虑OpenAI的ChatGPT和其他类似程序（人工智能研究人员称之为大型语言模型）时，施乐复印机的这一事件值得我们今天铭记。复印机和大型语言模型之间的相似性可能不会立即显现出来--但请考虑以下场景。想象一下，你即将永远失去对互联网的访问。在准备过程中，你计划创建一个网络上所有文本的压缩副本，这样你就可以把它存储在一个私人服务器上。不幸的是，你的私人服务器只有所需空间的百分之一；如果你希望所有的东西都能装下，你就不能使用无损压缩算法。相反，你写一个有损算法，识别文本中的统计规律性，并将其存储在一个专门的文件格式中。因为你有几乎无限的计算能力来完成这项任务，你的算法可以识别非常细微的统计规律性，这使你可以实现所需的一百比一的压缩率。

现在，失去互联网接入并不十分可怕；你已经把网络上的所有信息都储存在你的服务器上。唯一的问题是，由于文本已经被高度压缩，你不能通过搜索精确的引文来寻找信息；你永远不会得到一个精确的匹配，因为这些词并不是被存储的内容。为了解决这个问题，你要创建一个界面，接受以问题形式进行的查询，并以传达你服务器上的内容要点的答案进行回应。

我所描述的听起来很像ChatGPT，或者大多数其他的大型语言模型。把ChatGPT想象成网络上所有文本的一个模糊的jpeg。它保留了网络上的大部分信息，就像jpeg保留了高分辨率图像的大部分信息一样，但是，如果你在寻找一个精确的比特序列，你不会找到它；你所得到的只是一个近似值。但是，由于这个近似值是以语法文本的形式呈现的，而ChatGPT擅长创建这种文本，所以通常是可以接受的。你看到的仍然是一个模糊的jpeg，但模糊的发生方式并没有使整个图片看起来不那么清晰。

这种对有损压缩的类比不仅仅是理解ChatGPT通过使用不同的词来重新包装网络上的信息的一种方法。它也是理解 "幻觉 "的一种方式，即对事实问题的无意义回答，像ChatGPT这样的大型语言模型都很容易出现这种情况。这些幻觉是压缩人工制品，但就像施乐影印机产生的错误标签一样，它们足够可信，以至于识别它们需要与原件进行比较，在这种情况下，原件意味着网络或我们自己对世界的了解。当我们这样想的时候，这样的幻觉并不令人惊讶；如果一个压缩算法被设计成在丢弃了99%的原件后重建文本，我们应该想到它所生成的内容中的很大一部分将是完全捏造的。

当我们记得有损压缩算法使用的一个常见技术是插值--即通过查看缺口两侧的内容来估计缺少的内容，这个类比就更有意义了。当一个图像程序在显示一张照片时，必须重建一个在压缩过程中丢失的像素，它将查看附近的像素并计算平均值。这就是ChatGPT在被要求用《独立宣言》的风格来描述，比如说在烘干机里丢了一只袜子时所做的事情：它在 "词汇空间 "中取两点，并生成占据两点之间位置的文本。("在人类活动的过程中，人们有必要把他的衣服和他们的伙伴分开，以保持其清洁和秩序。..."）ChatGPT在这种形式的插值方面非常出色，以至于人们发现它很有趣：他们发现了一个用于段落而不是照片的 "模糊 "工具，并且玩得很开心。

鉴于像ChatGPT这样的大型语言模型经常被赞誉为人工智能的最前沿，把它们描述为有损失的文本压缩算法可能听起来不屑一顾，或者至少是放水。我确实认为这种观点为大型语言模型的拟人化倾向提供了有益的纠正，但压缩类比的另一个方面值得考虑。自2006年以来，一位名叫马库斯-胡特（Marcus Hutter）的人工智能研究员提供了一笔现金奖励--称为 "人类知识压缩奖"，或称 "胡特奖"--奖励任何能够无损压缩维基百科的特定一GB快照的人，使之比前一位获奖者的压缩量小。你可能已经遇到过使用zip文件格式压缩的文件。zip格式将胡特的一千兆字节文件减少到大约三百兆字节；最近的获奖者设法将其减少到一百一十兆字节。这并不仅仅是一个平滑的练习。胡特认为，更好的文本压缩将有助于创造人类水平的人工智能，部分原因是通过理解文本可以实现最大程度的压缩。

来自《纽约客》的视频

一位精神病学家为何收集预感

为了掌握压缩和理解之间的拟议关系，想象一下，你有一个包含一百万个加法、减法、乘法和除法例子的文本文件。虽然任何压缩算法都可以减少这个文件的大小，但实现最大压缩率的方法可能是推导出算术的原理，然后为计算器程序编写代码。使用计算器，你不仅可以完美地重建文件中的一百万个例子，还可以重建你将来可能遇到的任何其他算术的例子。同样的逻辑也适用于压缩维基百科的一个片段的问题。如果一个压缩程序知道力等于质量乘以加速度，那么它在压缩有关物理学的网页时就可以舍弃很多字，因为它能够重构这些字。同样，程序对供求关系了解得越多，它在压缩有关经济学的网页时就可以丢弃更多的词，等等。

大型语言模型可以识别文本中的统计规律性。对网络文本的任何分析都会发现，像 "供应量少 "这样的短语经常与 "价格上涨 "这样的短语紧紧相邻出现。当被问及关于供应短缺的影响的问题时，一个包含这种相关性的聊天机器人可能会回答关于价格上涨的答案。如果一个大型的语言模型编制了大量的经济术语之间的相关性--以至于它可以对各种各样的问题提供合理的回答--我们是否应该说它真正理解了经济理论？像ChatGPT这样的模型没有资格获得胡特奖，原因有很多，其中之一是它们没有精确地重建原文--也就是说，它们没有进行无损压缩。但是，他们的有损压缩还是表明了人工智能研究人员感兴趣的那种真正的理解，这可能吗？

让我们回到算术的例子上。如果你要求GPT-3（ChatGPT所依据的大型语言模型）对一对数字进行加减运算，当数字只有两位时，它几乎总是能做出正确的回答。但是当数字越大时，它的准确性就越差，当数字有五位数时，它的准确性就会下降到百分之十。GPT-3给出的大多数正确答案在网络上找不到--例如，没有多少网页包含 "245+821 "这样的文字，所以它不是在进行简单的记忆。但是，尽管摄取了大量的信息，它也没有能够推导出算术的原理。对GPT-3的错误答案的仔细检查表明，它在进行算术时并没有携带 "1"。网络上当然有关于携带 "1 "的解释，但GPT-3并没有能够纳入这些解释。GPT-3对算术实例的统计分析使其能够产生对真实事物的表面近似，但也仅此而已。

鉴于GPT-3在小学教授的科目上的失败，我们如何解释它有时在写大学水平的论文上似乎表现良好的事实？尽管大型语言模型经常出现幻觉，但当它们清醒时，听起来它们确实理解经济理论等科目。也许算术是一个特例，是大型语言模型不适合的情况。有没有可能，在加减法以外的领域，文本中的统计规律性实际上与现实世界的真正知识相对应？

我认为有一个更简单的解释。想象一下，如果ChatGPT是一种无损的算法，会是什么样子。如果是这样的话，它总是通过提供相关网页上的逐字引用来回答问题。我们可能会认为这个软件只比传统的搜索引擎有一点改进，而且对它的印象也不那么深刻。事实上，ChatGPT重新表述了网络上的材料，而不是逐字逐句地引用，这使得它看起来像是一个学生在用自己的语言表达想法，而不是简单地转述她所读到的东西；它创造了一种错觉，即ChatGPT理解了这些材料。在人类学生中，死记硬背并不是真正学习的指标，所以ChatGPT不能准确地引用网页上的内容，恰恰让我们认为它已经学到了什么。当我们在处理单词序列时，有损压缩看起来比无损压缩更聪明。

人们已经为大型语言模型提出了很多用途。把它们想成是模糊的jpeg，就可以评估它们可能或可能不适合做什么。让我们考虑几个场景。

大型语言模型可以取代传统的搜索引擎吗？为了让我们对它们有信心，我们需要知道它们没有被灌输宣传和阴谋论--我们需要知道jpeg正在捕捉网络的正确部分。但是，即使一个大型的语言模型只包括我们想要的信息，仍然存在着模糊性的问题。有一种模糊性是可以接受的，那就是用不同的词重新表述信息。还有一种模糊是完全的捏造，当我们在寻找事实时，我们认为这是不可接受的。目前还不清楚在技术上是否有可能保留可接受的模糊性而消除不可接受的模糊性，但我希望在不久的将来我们会发现这一点。

即使有可能限制大型语言模型参与捏造，我们是否应该用它们来生成网络内容？只有当我们的目标是重新包装网络上已有的信息时，这才有意义。有些公司就是为了做这个而存在的--我们通常称它们为内容制造厂。也许大型语言模型的模糊性对他们来说是有用的，这是一种避免侵犯版权的方法。不过，一般来说，我想说的是，任何对内容加工厂有利的东西对搜索信息的人来说都不是好事。这种类型的重新包装的兴起，使我们现在更难在网上找到我们要找的东西；由大型语言模型产生的文本在网上发布得越多，网络就越是成为自己的一个模糊的版本。

关于OpenAI即将推出的ChatGPT的继任者GPT-4，目前的信息非常少。但我要做一个预测：在收集用于训练GPT-4的大量文本时，OpenAI的人将尽一切努力排除ChatGPT或任何其他大型语言模型产生的材料。如果事实如此，它将作为无意的确认，大型语言模型和有损压缩之间的类比是有用的。反复保存jpeg会产生更多的压缩伪影，因为每次都会丢失更多的信息。这就相当于过去反复复印的数字文件。图像质量只会越来越差。

事实上，衡量一个大型语言模型质量的一个有用的标准可能是一个公司是否愿意使用它所产生的文本作为新模型的训练材料。如果ChatGPT的输出对GPT-4来说不够好，我们可以把它作为一个指标，认为它对我们也不够好。相反，如果一个模型开始生成的文本如此之好，以至于可以用来训练新的模型，那么这应该让我们对该文本的质量有信心。(我怀疑这样的结果需要在建立这些模型的技术上有重大突破）。如果当我们开始看到模型产生与输入一样好的输出时，那么有损压缩的类比就不再适用了。

大型语言模型能够帮助人类创作原创性的文字吗？要回答这个问题，我们需要具体了解这个问题的含义。有一种艺术流派被称为施乐艺术，或复印艺术，艺术家们利用复印机的独特属性作为创作工具。使用ChatGPT的复印机肯定可以达到这些目的，因此，在这个意义上，答案是肯定的。但我不认为有人会宣称复印机已经成为艺术创作中必不可少的工具；绝大多数艺术家在创作过程中不使用复印机，也没有人认为他们的这种选择会使自己处于不利地位。

因此，让我们假设我们不是在谈论一种类似于施乐艺术的新的写作类型。鉴于这一规定，大型语言模型生成的文本能否成为作家在写作原创作品时的一个有用的起点，无论是小说还是非小说？让一个大型语言模型来处理模板，是否能让作家们把注意力集中在真正有创意的部分？

显然，没有人可以代表所有的作家，但让我提出这样的论点：从非原创作品的模糊拷贝开始，并不是创作原创作品的好方法。如果你是一个作家，在你写出原创作品之前，你会写很多非原创作品。而花在这些非原创作品上的时间和精力并没有浪费；相反，我认为这正是使你最终能够创作出原创作品的原因。花费在选择正确的词和重新安排句子以更好地相互衔接上的时间，是教你如何通过散文传达意义的。让学生写文章不仅仅是测试他们对材料的掌握程度的一种方式，它还能让他们获得表达自己想法的经验。如果学生从来没有写过我们都读过的文章，他们就永远不会获得写我们从来没有读过的东西所需的技能。

而且，并不是说，一旦你不再是一个学生，你就可以安全地使用一个大的语言模型所提供的模板。表达思想的挣扎并不会在你毕业后就消失--它可能在你开始起草新作品时就发生了。有时，只有在写作过程中，你才会发现自己的原始想法。有些人可能会说，大型语言模型的输出看起来与人类作家的初稿没有什么不同，但是，我再次认为这是一种表面的相似性。你的初稿并不是一个表达清楚的非原创想法；它是一个表达不佳的原创想法，它伴随着你无定形的不满，你意识到它所说的和你希望它所说的之间的距离。这就是在重写过程中指导你的东西，这也是当你从人工智能生成的文本开始时缺乏的东西之一。

写作并没有什么神奇或神秘之处，但它所涉及的不仅仅是将现有文件放在不可靠的复印机上，然后按下打印按钮。有可能在未来，我们将建立一个人工智能，能够根据自己对世界的经验写出好的散文。我们实现这一目标的那一天将是非常重要的，但那一天远远超出我们的预测范围。在此期间，我们有理由问，拥有重新表述网络的东西有什么用？如果我们永远失去了对互联网的访问，并且不得不在一个空间有限的私人服务器上存储一个副本，那么像ChatGPT这样的大型语言模型可能是一个很好的解决方案，前提是它可以不被制造出来。但我们并没有失去对互联网的访问。那么，当你还有原件的时候，一张模糊的jpeg有多大用处呢？♦