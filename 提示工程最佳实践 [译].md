---
tags:
  - 写作gpts
---
# 提示工程最佳实践 \[译\]

原文：**[Prompt Engineering Best Practices](https://towardsdatascience.com/prompt-architecture-bd8a07117dab)**

**作者：**

**Sarah Chieng**

**注意：** 大家好，我是**[Sarah](https://twitter.com/SarahChieng)**！这个页面总结了一些当前流行的实践和技巧，用以提高大语言模型（LLM）输出的质量。

这份总结最初是基于 Andrew Ng 和 OpenAI 的 Isa Fulford 在 2023 年 12 月 11 日 NeurIPS 会议上的“利用大语言模型进行应用开发”教程中的提示工程部分。自那以后，我还增加了许多丰富的内容和示例。虽然这次演讲没有在线上发布，但希望这些详细而快速的笔记能为你提供一个很好的快速概览 :)

此外，还有来自 **[Swyx](https://twitter.com/swyx)**、**[Jerry Liu](https://twitter.com/messages/369777416-1502356865794985986)** 和 **[Brian Huang](https://twitter.com/brianryhuang)** 的许多新贡献。

**注意：这些技巧同样适用于日常人际交流哦 😉**

---

### 小贴士 #1：明确和具体的指令

**提供问题的详细背景**。减少模糊性可以降低产生不相关或错误输出的可能性。

您还可以**使用分隔符**来清晰地区分输入的不同部分。比如：章节标题、三重引号、三重反引号、三重破折号、尖括号、"####"。

**指定所期望的输出格式或输出长度**。一种方法是让模型扮演一个角色。例如：

“想象你是一个创意作家”

“请用大约两句话回答。”

“给我一个这段文本的总结。这里有我喜欢的总结示例 \__\_”

**提供示例**。比如，这是少样例提示（few-shot prompting）的步骤：

1. 第一个例子（第一个“shot”）：给出一个示例，展示输入和相应的输出/回应。

2. 第二个例子（第二个“shot”）：给出第二个输入和输出样例。

3. 你的输入：给出你的实际输入。现在，模型可以遵循前两个示例的规则来生成输出。

### 小贴士 #2：给模型思考的时间

模型在快速响应时更容易犯推理错误。

通过**要求模型进行一连串的推理**，可以促使它逐步、更细致地思考。你可以要求一个“思考过程”，或者指定具体的步骤。例如，这样简单的增加对提示的效果非常好：“**让我们一步步地思考。**”

比如，如果你让模型对学生的答案进行评分，可以这样指导模型：

- 第 1 步：先生成你自己对这个问题的答案

- 第 2 步：将你的答案与学生的答案进行比较

- 第 3 步：在评估学生的答案之前，完成你自己的答案计算

### 小贴士 #3：多次提问

让模型多次回答同一个问题，并从中选择最佳答案。当准确性非常重要时（而不是响应速度或成本），可以使用不同的提示来生成多个回答。

以下是一些可以调整的要素：

- **温度**：调节 LLM 回应的随机性或创造性。更高的温度可以产生更多样化、创意十足的回应。较低的温度则产生更保守、可预测的回应。

- **Shot（示例数）**：指在提示中给出的示例数量（“Shot”）。零次即不提供示例，一次即提供一个示例，以此类推。

- **提示词**：更直接或更间接地提问，要求解释，进行比较等。

### 小贴士 #4：引导模型

以下是一些示例：

- **如果文件过长，** 模型可能会提前停止阅读。你可以引导模型分段处理长文档，并递归地构建完整的总结。

- **帮助它自我纠正**。如果模型开始就走错方向，它很难自我纠正。"我从你那里得到了关于量子物理的解释，你确定你的答案正确吗？能否重新审视并提供一个从量子力学基础开始的正确解释？"

- **避免提出引导性问题**。模型会倾向于取悦用户，所以要引导但同时要保持提示词的开放性。

   - “电子游戏会导致暴力吗？” ❌

   - “我想要一个关于电子游戏与行为关系研究结果的客观概述。” ✅

### 小贴士 #5：分解任务或提示词

**将复杂任务分解成多个简单任务**。这样做有助于降低错误率，因为复杂任务的错误率通常高于简单任务。

你可以使用**意图分类**来确定最相关的指令，然后将响应结合起来形成连贯的输出。例如：

- **查询：** "我要去巴黎待三天，我需要知道该带什么、哪里餐厅最好，以及如何使用公共交通。"

- **分解：**

   - 意图 1：为去巴黎的旅行准备行李。

   - 意图 2：推荐巴黎最佳餐厅。

   - 意图 3：关于如何使用巴黎公共交通的指导。

- **LLM 回应：** AI 将分别处理每个意图，针对巴黎的行李准备、餐饮选择和交通方式提供定制化建议，然后将这些整合成一个全面的回答。

或者，如果子任务之间有联系，

- 第 1 步：将任务分解成多个查询

- 第 2 步：将第一个查询的输出用作下一个查询的输入

\*\*\* 注意：这样也可以降低成本，因为每个步骤的成本都会更低\*

### 小贴士 #6：使用外部工具

通常，**如果某个任务可以通过工具而不是语言模型以更可靠或更高效的方式完成，那么最好借助外部工具**，以便充分利用二者的优势。

以下是一些可用的工具示例：

- **计算器：** LLM 在数学方面表现不佳。它们本质上是生成 token/词汇，而非数字。使用计算器可以显著提高 LLM 的数学处理能力。

- **RAG: 连接 LLM，智能地检索信息，而不是尝试将其纳入上下文窗口。例如，[Metaphor's](https://metaphor.systems/) 网络搜索检索 API** 😉 — 有兴趣可以给我发邮件获取免费访问哈哈

- \*\*代码执行：\*\*利用代码执行或调用外部 API 来执行和测试模型创建的代码。

- \*\*外部函数：\*\*为模型定义函数调用。例如，`send_email()`、`get_current_weather()`、`get_customers()`。在你那边执行这些函数，并将响应返回给模型。

---

希望大家喜欢 🙂 感谢 **[Swyx](https://twitter.com/swyx)**、**[Jerry Liu](https://twitter.com/messages/369777416-1502356865794985986)** 和 **[Brian Huang](https://twitter.com/brianryhuang)** 的反馈和建议。

此外，这份文件是一份**正在进行的工作**，理想中它能成为一个非常有用的资源。欢迎提供任何反馈或补充（可以通过 Twitter 联系我：**[@sarahchieng](https://twitter.com/SarahChieng)** 或 💌 **[sarah@metaphor.so](sarah@metaphor.so)**）

祝好，

Sarah

**[Twitter](https://twitter.com/SarahChieng)** | **[LinkedIn](https://www.linkedin.com/in/sarah-chieng-888595139/)**