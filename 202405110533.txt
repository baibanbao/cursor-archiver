示词官方指南

OpenAI 发布的提示工程指南，这份指南分享了如何更有效地利用像如 GPT-4 这样的大语言模型（有时候也叫 GPT 模型）来获得更好的结果。介绍的方法可以相互结合，以发挥更大的作用。希望你也可以从中学习到适合你的技巧。

另外，这份指南的示例主要针对 GPT-4 模型，但理论上来说也适用其他模型。

其中主要有六个策略，每个策略下再有具体的技巧。

策略一：撰写清晰的指令

这些模型并不会读心术，无法猜到你的想法。如果模型的输出内容过长，你可以要求它简短回答。如果模型输出内容过于简单，你可以要求使用更专业的水平写作。如果你对输出格式不满意，可以直接展示你期望的格式。最好就是让模型不需要去猜你想要什么，这样你最有可能获得想要的结果。

技巧：

在查询中添加详细信息，以获得更准确的答案

请求模型扮演特定角色

使用分隔符来清晰区分输入的不同部分

明确指出完成任务需要的步骤

提供实例作为参考

明确指定希望输出的长度

策略二：提供参考文本

语言模型可能会自信地编造出虚假答案，特别是当回应一些深奥主题或被要求提供引文和 URLs 时。就像学生在考试中借助笔记能够帮助其取得更好的成绩一样，为这类模型提供参考文本也可减少其制造虚假信息的情况。

技巧：

引导模型根据参考文本回答问题

引导模型根据参考文本中的引用信息回答问题

策略三：把复杂的任务拆分成简单的子任务

就像在软件工程中，我们会习惯于把复杂的系统分解成一套模块化的组件，对于提交给语言模型的任务也是同样的道理。相较于简单的任务，复杂任务的错误率往往会更高。而更进一步，我们常常可以把这些复杂任务重新设定为一系列的工作流程，每一个流程就是一个更简单的任务，而且这些任务之间是相互联系的，前一个任务的输出会作为后一个任务的输入。

技巧：

利用意图分类识别用户查询中最相关的指令

对于需要长时间对话的对话应用，总结或筛选先前的对话内容

分步总结长文档，并递归地构建完整的总结

策略四：给模型更多时间“思考”

如果被要求计算 17 乘以 28，我们可能不能立即给出答案，但可以花一些时间逐步计算出结果。同样，在 AI 模型试图立刻回答问题时，往往比理性思考后再做出回答更容易出错。所以，在模型给出答案之前，要求其展示一下"思考过程"，有助于模型更可靠地推导出正确的答案。

技巧：

在仓促做出结论前，指导模型自己寻找解决方法

通过内心独白或连串问题来掩盖模型的思考过程

问模型在之前的步骤中是否有遗漏

策略五：运用外部工具

为了弥补模型的不足，我们可以利用其他工具的输出作为输入。例如，文本检索系统（有时被称为 RAG 或检索增强生成系统）可以向模型提供相关文档的信息。像 OpenAI 的代码执行引擎这样的工具，可以帮助模型进行数学运算和代码执行。如果某项任务通过工具来完成能比通过语言模型更可靠或更高效，那么就把任务交给这个工具处理，这样就能结合两者长处，达到最佳效果。

技巧：

运用基于嵌入的搜索来高效实现知识检索

利用代码执行进行更精确的计算或调用外部 API

使模型能够访问特定功能

策略六：系统地对变更进行测试

如果能对性能进行量化，那么就能更好地提高性能。有时，对提示词的修改在少数特定例子上可能表现更佳，但在更具普遍性的样本集上可能会导致整体性能下降。因此，为了确保改动对总体性能产生积极的影响，可能需要设计一份全方位的测试（也被称为"评估"）。

技巧：

根据标准答案的参考评估模型输出效果

对于上面提到的每一种技巧，都有非常详细的参考示例。

官网链接：https://platform.openai.com/docs/guides/prompt-engineering
中文翻译：https://baoyu.io/translations/openai/openai-prompt-engineering-guides
Translate post